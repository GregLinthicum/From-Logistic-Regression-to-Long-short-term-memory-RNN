# From-Logistic-Regression-to-Long-short-term-memory-RNN
As the technology emerges from the state where the machine did not even get the words you were uttering and responded in a choppy robotic way to the open space of the creativity unimaginable ever before some basic code snippets never age. 

Taxonomy

Supervider Learning

    Artificial NeuralNetworks ( ANN )
    Multilayer Perceptrons (MLPs)
    Convolutional Neural Networks (CNNs)
    Recurrent Neural Networks (RNNs)
    Long short-term memory (LSTM) 
    
    
Unsupervised Learning

    Self-Organizing Maps (SOM)
    Restricted Boltzman Machines (RBM)
    Deep Boltzman Machines (DBM)
    Deep Believe Networks (DBN)
    Auto-Encoders (AE)
        Sparse Auto-Encoder (SAE)
        Stacked Auto-Encoder (SAE)
        Stacked Sparse Auto-Encoder (SSAE)





Main Application
Supervider Learning
    
    Artificial NeuralNetworks ( ANN )
    Used mainly for Regression and Classification
    
    Multilayer Perceptrons (MLPs)
    
   
    Convolutional Neural Networks (CNNs)
    Used Mainly for Machine Vision
   
    Recurrent Neural Networks (RNNs)
    Usedmainly for Time Series Anaalysis
    
    Long short-term memory (LSTM) 
    
    
Unsupervised Learning
    
    Self-Organizing Maps (SOM)
    Used mainly for Feature Detection
   
    Restricted Boltzman Machines (RBM)
    
    Deep Boltzman Machines (DBM)
    Used Mainly for Recommendation Systems.
    
    Deep Believe Networks (DBN)
    Difference between Deep Belief and Deep Boltzman is that Deep Boltzman is bidirectional on every level.
    
    Auto-Encoders (AE)
    Used Mainly for Recommendation Systems

    https://medium.com/@venkatakrishna.jonnalagadda/sparse-stacked-and-variational-autoencoder-efe5bfe73b64

